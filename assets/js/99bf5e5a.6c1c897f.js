"use strict";(self.webpackChunkdocusaurus=self.webpackChunkdocusaurus||[]).push([[456],{3905:(e,t,n)=>{n.d(t,{Zo:()=>l,kt:()=>h});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var p=a.createContext({}),m=function(e){var t=a.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},l=function(e){var t=m(e.components);return a.createElement(p.Provider,{value:t},e.children)},d="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,p=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),d=m(n),u=r,h=d["".concat(p,".").concat(u)]||d[u]||c[u]||o;return n?a.createElement(h,i(i({ref:t},l),{},{components:n})):a.createElement(h,i({ref:t},l))}));function h(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=u;var s={};for(var p in t)hasOwnProperty.call(t,p)&&(s[p]=t[p]);s.originalType=e,s[d]="string"==typeof e?e:r,i[1]=s;for(var m=2;m<o;m++)i[m]=n[m];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},2403:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>i,default:()=>c,frontMatter:()=>o,metadata:()=>s,toc:()=>m});var a=n(7462),r=(n(7294),n(3905));const o={},i="Embeddings",s={unversionedId:"components/embeddings",id:"components/embeddings",title:"Embeddings",description:"Embeddings are vector representations of text that capture the semantic meaning of the text. They are created using text embedding models and allow us to think about the text in a vector space, enabling us to perform tasks like semantic search, where we look for pieces of text that are most similar in the vector space.",source:"@site/docs/components/embeddings.mdx",sourceDirName:"components",slug:"/components/embeddings",permalink:"/components/embeddings",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"docs",previous:{title:"Chains",permalink:"/components/chains"},next:{title:"LLMs",permalink:"/components/llms"}},p={},m=[{value:"CohereEmbeddings",id:"cohereembeddings",level:3},{value:"HuggingFaceEmbeddings",id:"huggingfaceembeddings",level:3},{value:"OpenAIEmbeddings",id:"openaiembeddings",level:3}],l={toc:m},d="wrapper";function c(e){let{components:t,...n}=e;return(0,r.kt)(d,(0,a.Z)({},l,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"embeddings"},"Embeddings"),(0,r.kt)("p",null,"Embeddings are vector representations of text that capture the semantic meaning of the text. They are created using text embedding models and allow us to think about the text in a vector space, enabling us to perform tasks like semantic search, where we look for pieces of text that are most similar in the vector space."),(0,r.kt)("hr",null),(0,r.kt)("h3",{id:"cohereembeddings"},"CohereEmbeddings"),(0,r.kt)("p",null,"Used to load ",(0,r.kt)("a",{parentName:"p",href:"https://cohere.com/"},"Cohere\u2019s")," embedding models."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Params")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"cohere_api_key:")," Holds the API key required to authenticate with the Cohere service.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"model:")," The language model used for embedding text documents and performing queries \u2014defaults to ",(0,r.kt)("inlineCode",{parentName:"p"},"embed-english-v2.0"),".")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"truncate:")," Used to specify whether or not to truncate the input text. Truncation is useful when dealing with long texts that exceed the model's maximum input length. By truncating the text, the user can ensure that it fits within the model's constraints."))),(0,r.kt)("hr",null),(0,r.kt)("h3",{id:"huggingfaceembeddings"},"HuggingFaceEmbeddings"),(0,r.kt)("p",null,"Used to load ",(0,r.kt)("a",{parentName:"p",href:"https://huggingface.co"},"HuggingFace\u2019s")," embedding models."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Params")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"cache_folder:")," Used to specify the folder where the embeddings will be cached. When embeddings are computed for a text, they can be stored in the cache folder so that they can be reused later without the need to recompute them. This can improve the performance of the application by avoiding redundant computations.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"encode_kwargs:")," Used to pass additional keyword arguments to the encoding method of the underlying HuggingFace model. These keyword arguments can be used to customize the encoding process, such as specifying the maximum length of the input sequence or enabling truncation or padding.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"model_kwargs:")," Used to customize the behavior of the model, such as specifying the model architecture, the tokenizer, or any other model-specific configuration options. By using ",(0,r.kt)("inlineCode",{parentName:"p"},"model_kwargs"),", the user can configure the HuggingFace model according to specific needs and preferences.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"model_name:")," Used to specify the name or identifier of the HuggingFace model that will be used for generating embeddings. It allows users to choose a specific pre-trained model from the Hugging Face model hub \u2014 defaults to ",(0,r.kt)("inlineCode",{parentName:"p"},"sentence-transformers/all-mpnet-base-v2"),"."))),(0,r.kt)("hr",null),(0,r.kt)("h3",{id:"openaiembeddings"},"OpenAIEmbeddings"),(0,r.kt)("p",null,"Used to load ",(0,r.kt)("a",{parentName:"p",href:"https://openai.com/"},"OpenAI\u2019s")," embedding models."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Params")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"chunk_size:")," Determines the maximum size of each chunk of text that is processed for embedding. If any of the incoming text chunks exceeds ",(0,r.kt)("inlineCode",{parentName:"p"},"chunk_size")," characters, it will be split into multiple chunks of size ",(0,r.kt)("inlineCode",{parentName:"p"},"chunk_size")," or less before being embedded \u2014 defaults to ",(0,r.kt)("inlineCode",{parentName:"p"},"1000"),".")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"deployment:")," Used to specify the deployment name or identifier of the text embedding model. It allows the user to choose a specific deployment of the model to use for embedding. When the deployment is provided, this can be useful when the user has multiple deployments of the same model with different configurations or versions \u2014 defaults to ",(0,r.kt)("inlineCode",{parentName:"p"},"text-embedding-ada-002"),".")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"embedding_ctx_length:")," This parameter determines the maximum context length for the text embedding model. It specifies the number of tokens that the model considers when generating embeddings for a piece of text \u2014 defaults to ",(0,r.kt)("inlineCode",{parentName:"p"},"8191")," (this means that the model will consider up to 8191 tokens when generating embeddings).")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"max_retries:")," Determines the maximum number of times to retry a request if the model provider returns an error from their API \u2014 defaults to ",(0,r.kt)("inlineCode",{parentName:"p"},"6"),".")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"model:")," Defines which pre-trained text embedding model to use \u2014 defaults to ",(0,r.kt)("inlineCode",{parentName:"p"},"text-embedding-ada-002"),".")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"openai_api_base:")," Refers to the base URL for the Azure OpenAI resource. It is used to configure the API to connect to the Azure OpenAI service. The base URL can be found in the Azure portal under the user Azure OpenAI resource.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"openai_api_key:")," Is used to authenticate and authorize access to the OpenAI service.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"openai_api_type:")," Is used to specify the type of OpenAI API being used, either the regular OpenAI API or the Azure OpenAI API. This parameter allows the ",(0,r.kt)("inlineCode",{parentName:"p"},"OpenAIEmbeddings")," class to connect to the appropriate API service.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"openai_api_version:")," Is used to specify the version of the OpenAI API being used. This parameter allows the ",(0,r.kt)("inlineCode",{parentName:"p"},"OpenAIEmbeddings")," class to connect to the appropriate version of the OpenAI API service.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"openai_organization:")," Is used to specify the organization associated with the OpenAI API key. If not provided, the default organization associated with the API key will be used.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"openai_proxy:")," Proxy enables better budgeting and cost management for making OpenAI API calls, including more transparency into pricing.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"request_timeout:")," Used to specify the maximum amount of time, in milliseconds, to wait for a response from the OpenAI API when generating embeddings for a given text.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"tiktoken_model_name:")," Used to count the number of tokens in documents to constrain them to be under a certain limit. By default, when set to None, this will be the same as the embedding model name."))))}c.isMDXComponent=!0}}]);