"use strict";(self.webpackChunkdocusaurus=self.webpackChunkdocusaurus||[]).push([[892],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>h});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=a.createContext({}),c=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=c(e.components);return a.createElement(s.Provider,{value:t},e.children)},p="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),p=c(n),d=o,h=p["".concat(s,".").concat(d)]||p[d]||m[d]||r;return n?a.createElement(h,i(i({ref:t},u),{},{components:n})):a.createElement(h,i({ref:t},u))}));function h(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,i=new Array(r);i[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[p]="string"==typeof e?e:o,i[1]=l;for(var c=2;c<r;c++)i[c]=n[c];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},3414:(e,t,n)=>{n.d(t,{Z:()=>i});var a=n(7294),o=n(941),r=n(4996);const i=e=>{let{alt:t,sources:n}=e;const[i,l]=(0,a.useState)(!1),s=e=>{"Escape"===e.key&&l(!1)};return(0,a.useEffect)((()=>(i?document.addEventListener("keydown",s):document.removeEventListener("keydown",s),()=>{document.removeEventListener("keydown",s)})),[i]),a.createElement("div",{className:"zoomable-image "+(i?"fullscreen":""),onClick:()=>{l(!i)}},a.createElement(o.Z,{className:"zoomable-image-inner",alt:t,sources:{light:(0,r.Z)(n.light),dark:(0,r.Z)(n.dark)}}))}},6473:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>l,default:()=>d,frontMatter:()=>i,metadata:()=>s,toc:()=>u});var a=n(7462),o=(n(7294),n(3905)),r=(n(941),n(4996),n(3414));const i={},l="Conversation Chain",s={unversionedId:"conversation-chain",id:"conversation-chain",title:"Conversation Chain",description:"This example shows how to instantiate a simple ConversationChain component using a Language Model (LLM). Once the Node Status turns green \ud83d\udfe2, the chat will be ready to take in user messages. Here, we used ChatOpenAI to act as the required LLM input, but you can use any LLM for this purpose.",source:"@site/docs/conversation-chain.mdx",sourceDirName:".",slug:"/conversation-chain",permalink:"/conversation-chain",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"docs",previous:{title:"Collection",permalink:"/collection"},next:{title:"Buffer Memory",permalink:"/buffer-memory"}},c={},u=[{value:"\u26d3\ufe0f LangFlow Example",id:"\ufe0f-langflow-example",level:2},{value:'<a target="_blank" href="json_files/Basic_Chat.json" download>Download Flow</a>',id:"download-flow",level:4}],p={toc:u},m="wrapper";function d(e){let{components:t,...n}=e;return(0,o.kt)(m,(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"conversation-chain"},"Conversation Chain"),(0,o.kt)("p",null,"This example shows how to instantiate a simple ",(0,o.kt)("inlineCode",{parentName:"p"},"ConversationChain")," component using a Language Model (LLM). Once the Node Status turns green \ud83d\udfe2, the chat will be ready to take in user messages. Here, we used ",(0,o.kt)("inlineCode",{parentName:"p"},"ChatOpenAI")," to act as the required LLM input, but you can use any LLM for this purpose."),(0,o.kt)("admonition",{type:"info"},(0,o.kt)("p",{parentName:"admonition"},"Make sure to always get the API key from the provider.")),(0,o.kt)("h2",{id:"\ufe0f-langflow-example"},"\u26d3\ufe0f LangFlow Example"),(0,o.kt)(r.Z,{alt:"Docusaurus themed image",sources:{light:"img/basic-chat.png"},mdxType:"ZoomableImage"}),(0,o.kt)("h4",{id:"download-flow"},(0,o.kt)("a",{target:"\\_blank",href:"json_files/Basic_Chat.json",download:!0},"Download Flow")),(0,o.kt)("admonition",{title:"LangChain Components \ud83e\udd9c\ud83d\udd17",type:"note"},(0,o.kt)("ul",{parentName:"admonition"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://python.langchain.com/docs/modules/chains/"},(0,o.kt)("inlineCode",{parentName:"a"},"ConversationChain"))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"https://python.langchain.com/docs/modules/model_io/models/chat/integrations/openai"},(0,o.kt)("inlineCode",{parentName:"a"},"ChatOpenAI"))))))}d.isMDXComponent=!0}}]);