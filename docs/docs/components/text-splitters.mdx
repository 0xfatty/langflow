import Admonition from "@theme/Admonition";

# Text Splitters

A text splitter is a tool that divides a document or text into smaller chunks or segments. It is used to break down large texts into more manageable pieces for analysis or processing.


### Character Text Splitter

The CharacterTextSplitter is used to split a long text into smaller chunks based on a specified character. It splits the text by trying to keep paragraphs, sentences, and words together as long as possible, as these are semantically related pieces of text.

**Params**

- **Input:** The input text or document to be split.
- **Chunk Overlap:** The number of characters by which adjacent chunks overlap. Defaults to 200.
- **Chunk Size:** The maximum number of characters in each chunk. Defaults to 1000.
- **Separator:** The separator used to join chunks. Defaults to "\n".

This component is useful for breaking down large text documents into smaller, more manageable chunks for further processing.

---

### Language Recursive Text Splitter

This component helps streamline the process of breaking down large pieces of text written in different programming languages into smaller, more digestible chunks, making it easier to work with them in downstream tasks or applications.

**Params**

- **Input:** The input text or document to be split.
- **Separator Type:** The type of separator to use, based on the selected language.
- **Separators:** The characters to split on. (Not shown)
- **Chunk Size:** The maximum length of each chunk. Defaults to 1000.
- **Chunk Overlap:** The amount of overlap between chunks. Defaults to 200.

--- 

### Recursive Character Text Splitter

Split text into chunks of a specified length.

**Params**

- **Input:** The texts or documents to split.
- **Separators:** The characters to split on. If left empty, defaults to ["\n\n", "\n", " ", ""].
- **Chunk Size:** The maximum length of each chunk. Defaults to 1000.
- **Chunk Overlap:** The amount of overlap between chunks. Defaults to 200.

This component is particularly useful for breaking down large text documents into smaller segments based on language-specific characteristics, enabling more granular text analysis and processing.