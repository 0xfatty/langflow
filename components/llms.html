<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-components/llms">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">LLMs | Langflow Documentation</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://logspace-ai.github.io/components/llms"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="LLMs | Langflow Documentation"><meta data-rh="true" name="description" content="We appreciate your understanding as we polish our documentation – it may contain some rough edges. Share your feedback or report issues to help us improve! 🛠️📝"><meta data-rh="true" property="og:description" content="We appreciate your understanding as we polish our documentation – it may contain some rough edges. Share your feedback or report issues to help us improve! 🛠️📝"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://logspace-ai.github.io/components/llms"><link data-rh="true" rel="alternate" href="https://logspace-ai.github.io/components/llms" hreflang="en"><link data-rh="true" rel="alternate" href="https://logspace-ai.github.io/components/llms" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.56c3656a.css">
<link rel="preload" href="/assets/js/runtime~main.9bb0729e.js" as="script">
<link rel="preload" href="/assets/js/main.7b375ee0.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:#B53D38;color:#fff" role="banner"><div class="content_knG7 announcementBarContent_xLdY">⭐️ If you like ⛓️Langflow, star it on <a target="_blank" rel="noopener noreferrer" href="https://github.com/logspace-ai/langflow">GitHub</a>! ⭐️</div></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/chain.png" alt="Langflow" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/chain.png" alt="Langflow" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Langflow</b></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/logspace-ai/langflow" target="_blank" class="navbar__item navbar__link header-github-link"></a><a href="https://twitter.com/logspace_ai" target="_blank" class="navbar__item navbar__link header-twitter-link"></a><a href="https://discord.gg/EqksyE2EX9" target="_blank" class="navbar__item navbar__link header-discord-link"></a><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd sidebarWithHideableNavbar_wUlq"><a tabindex="-1" class="sidebarLogo_isFc" href="/"><img src="/img/chain.png" alt="Langflow" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/chain.png" alt="Langflow" class="themedImage_ToTc themedImage--dark_i4oU"><b>Langflow</b></a><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="true" href="/">Getting Started</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/">👋 Welcome to Langflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/installation">📦 How to install?</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/hugging-face-spaces">🤗 HuggingFace Spaces</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/getting-started/creating-flows">🎨 Creating Flows</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="true" href="/guidelines/components">Guidelines</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/guidelines/components">Component</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/guidelines/features">Features</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/guidelines/collection">Collection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/guidelines/prompt-customization">Prompt Customization</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/guidelines/chat-interface">Chat Interface</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/components/agents">Component Reference</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/components/agents">Agents</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/components/chains">Chains</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/components/embeddings">Embeddings</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/components/llms">LLMs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/components/loaders">Loaders</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/components/memories">Memories</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/components/prompts">Prompts</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/components/retrievers">Retrievers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/components/text-splitters">Text Splitters</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/components/toolkits">Toolkits</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/components/tools">Tools</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/components/vector-stores">Vector Stores</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/components/wrappers">Wrappers</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="true" href="/guides/loading_document">Step-by-Step Guides</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/guides/loading_document">Integrating documents with prompt variables</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/guides/chatprompttemplate_guide">Building chatbots with System Message</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="true" href="/examples/conversation-chain">Examples</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/examples/conversation-chain">Conversation Chain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/examples/buffer-memory">Buffer Memory</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/examples/midjourney-prompt-chain">MidJourney Prompt Chain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/examples/csv-loader">CSV Loader</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/examples/serp-api-tool">Serp API Tool</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/examples/multiple-vectorstores">Multiple Vector Stores</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/examples/python-function">Python Function</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/examples/how-upload-examples">📚 How to Upload Examples?</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="true" href="/deployment/gcp-deployment">Deployment</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/deployment/gcp-deployment">Deploy on Google Cloud Platform</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/deployment/jina-deployment">Deploy on Jina AI Cloud</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="true" href="/contributing/how-contribute">Contributing</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/contributing/how-contribute">How to contribute?</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/contributing/github-issues">GitHub Issues</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/contributing/community">Community</a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Component Reference</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">LLMs</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>LLMs</h1><div class="theme-admonition theme-admonition-caution alert alert--warning admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy">🚧</span>ZONE UNDER CONSTRUCTION</div><div class="admonitionContent_S0QG"><p>We appreciate your understanding as we polish our documentation – it may contain some rough edges. Share your feedback or report issues to help us improve! 🛠️📝</p></div></div><p>An LLM stands for Large Language Model. It is a core component of Langflow and provides a standard interface for interacting with different LLMs from various providers such as OpenAI, Cohere, and HuggingFace. LLMs are used widely throughout Langflow, including in chains and agents. They can be used to generate text based on a given prompt (or input).</p><hr><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="anthropic">Anthropic<a href="#anthropic" class="hash-link" aria-label="Direct link to Anthropic" title="Direct link to Anthropic">​</a></h3><p>Wrapper around Anthropic&#x27;s large language models. Find out more at <a href="https://www.anthropic.com" target="_blank" rel="noopener noreferrer">Anthropic</a>.</p><ul><li><p><strong>anthropic_api_key:</strong> Used to authenticate and authorize access to the Anthropic API.</p></li><li><p><strong>anthropic_api_url:</strong> Specifies the URL of the Anthropic API to connect to.</p></li><li><p><strong>temperature:</strong> Tunes the degree of randomness in text generations. Should be a non-negative value.</p></li></ul><hr><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="chatanthropic">ChatAnthropic<a href="#chatanthropic" class="hash-link" aria-label="Direct link to ChatAnthropic" title="Direct link to ChatAnthropic">​</a></h3><p>Wrapper around Anthropic&#x27;s large language model used for chat-based interactions. Find out more at <a href="https://www.anthropic.com" target="_blank" rel="noopener noreferrer">Anthropic</a>.</p><ul><li><p><strong>anthropic_api_key:</strong> Used to authenticate and authorize access to the Anthropic API.</p></li><li><p><strong>anthropic_api_url:</strong> Specifies the URL of the Anthropic API to connect to.</p></li><li><p><strong>temperature:</strong> Tunes the degree of randomness in text generations. Should be a non-negative value.</p></li></ul><hr><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="ctransformers">CTransformers<a href="#ctransformers" class="hash-link" aria-label="Direct link to CTransformers" title="Direct link to CTransformers">​</a></h3><p>The <code>CTransformers</code> component provides access to the Transformer models implemented in C/C++ using the <a href="https://github.com/ggerganov/ggml" target="_blank" rel="noopener noreferrer">GGML</a> library.</p><div class="theme-admonition theme-admonition-info alert alert--info admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_S0QG"><p>Make sure to have the <code>ctransformers</code> python package installed. Learn more about installation, supported models, and usage <a href="https://github.com/marella/ctransformers" target="_blank" rel="noopener noreferrer">here</a>.</p></div></div><p><strong>config:</strong> Configuration for the Transformer models. Check out <a href="https://github.com/marella/ctransformers#config" target="_blank" rel="noopener noreferrer">config</a>. Defaults to:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;top_k&quot;: 40,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;top_p&quot;: 0.95,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;temperature&quot;: 0.8,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;repetition_penalty&quot;: 1.1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;last_n_tokens&quot;: 64,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;seed&quot;: -1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;max_new_tokens&quot;: 256,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;stop&quot;: null,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;stream&quot;: false,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;reset&quot;: true,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;batch_size&quot;: 8,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;threads&quot;: -1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;context_length&quot;: -1,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;gpu_layers&quot;: 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>model:</strong> The path to a model file or directory or the name of a Hugging Face Hub model repo.</p><p><strong>model_file:</strong> The name of the model file in the repo or directory.</p><p><strong>model_type:</strong> Transformer model to be used. Learn more <a href="https://github.com/marella/ctransformers" target="_blank" rel="noopener noreferrer">here</a>.</p><hr><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="chatopenai">ChatOpenAI<a href="#chatopenai" class="hash-link" aria-label="Direct link to ChatOpenAI" title="Direct link to ChatOpenAI">​</a></h3><p>Wrapper around <a href="https://openai.com" target="_blank" rel="noopener noreferrer">OpenAI&#x27;s</a> chat large language models. This component supports some of the LLMs (Large Language Models) available by OpenAI and is used for tasks such as chatbots, Generative Question-Answering (GQA), and summarization.</p><ul><li><strong>max_tokens:</strong> The maximum number of tokens to generate in the completion. <code>-1</code> returns as many tokens as possible, given the prompt and the model&#x27;s maximal context size – defaults to <code>256</code>.</li><li><strong>model_kwargs:</strong> Holds any model parameters valid for creating non-specified calls.</li><li><strong>model_name:</strong> Defines the OpenAI chat model to be used.</li><li><strong>openai_api_base:</strong> Used to specify the base URL for the OpenAI API. It is typically set to the API endpoint provided by the OpenAI service.</li><li><strong>openai_api_key:</strong>  Key used to authenticate and access the OpenAI API.</li><li><strong>temperature:</strong> Tunes the degree of randomness in text generations. Should be a non-negative value – defaults to <code>0.7</code>.</li></ul><hr><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="cohere">Cohere<a href="#cohere" class="hash-link" aria-label="Direct link to Cohere" title="Direct link to Cohere">​</a></h3><p>Wrapper around <a href="https://cohere.com" target="_blank" rel="noopener noreferrer">Cohere&#x27;s</a> large language models.</p><ul><li><strong>cohere_api_key:</strong> Holds the API key required to authenticate with the Cohere service.</li><li><strong>max_tokens:</strong> Maximum number of tokens to predict per generation – defaults to <code>256</code>.</li><li><strong>temperature:</strong> Tunes the degree of randomness in text generations. Should be a non-negative value – defaults to <code>0.75</code>.</li></ul><hr><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="huggingfacehub">HuggingFaceHub<a href="#huggingfacehub" class="hash-link" aria-label="Direct link to HuggingFaceHub" title="Direct link to HuggingFaceHub">​</a></h3><p>Wrapper around <a href="https://www.huggingface.co/models" target="_blank" rel="noopener noreferrer">HuggingFace</a> models.</p><div class="theme-admonition theme-admonition-info alert alert--info admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_S0QG"><p>The HuggingFace Hub is an online platform that hosts over 120k models, 20k datasets, and 50k demo apps, all of which are open-source and publicly available. Discover more at <a href="http://www.huggingface.co" target="_blank" rel="noopener noreferrer">HuggingFace</a>.</p></div></div><ul><li><strong>huggingfacehub_api_token:</strong> Token needed to authenticate the API.</li><li><strong>model_kwargs:</strong> Keyword arguments to pass to the model.</li><li><strong>repo_id:</strong> Model name to use – defaults to <code>gpt2</code>.</li><li><strong>task:</strong> Task to call the model with. Should be a task that returns <code>generated_text</code> or <code>summary_text</code>.</li></ul><hr><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="llamacpp">LlamaCpp<a href="#llamacpp" class="hash-link" aria-label="Direct link to LlamaCpp" title="Direct link to LlamaCpp">​</a></h3><p>The <code>LlamaCpp</code> component provides access to the <code>llama.cpp</code> models.</p><div class="theme-admonition theme-admonition-info alert alert--info admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_S0QG"><p>Make sure to have the <code>llama.cpp</code> python package installed. Learn more about installation, supported models, and usage <a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener noreferrer">here</a>.</p></div></div><ul><li><strong>echo:</strong> Whether to echo the prompt – defaults to <code>False</code>.</li><li><strong>f16_kv:</strong> Use half-precision for key/value cache – defaults to <code>True</code>.</li><li><strong>last_n_tokens_size:</strong> The number of tokens to look back at when applying the repeat_penalty. Defaults to <code>64</code>.</li><li><strong>logits_all:</strong> Return logits for all tokens, not just the last token Defaults to <code>False</code>.</li><li><strong>logprobs:</strong> The number of logprobs to return. If None, no logprobs are returned.</li><li><strong>lora_base:</strong> The path to the Llama LoRA base model.</li><li><strong>lora_path:</strong> The path to the Llama LoRA. If None, no LoRa is loaded.</li><li><strong>max_tokens:</strong> The maximum number of tokens to generate. Defaults to <code>256</code>.</li><li><strong>model_path:</strong> The path to the Llama model file.</li><li><strong>n_batch:</strong> Number of tokens to process in parallel. Should be a number between 1 and n_ctx. Defaults to <code>8</code>.</li><li><strong>n_ctx:</strong> Token context window. Defaults to <code>512</code>.</li><li><strong>n_gpu_layers:</strong> Number of layers to be loaded into GPU memory. Default None.</li><li><strong>n_parts:</strong>Number of parts to split the model into. If -1, the number of parts is automatically determined. Defaults to <code>-1</code>.</li><li><strong>n_threads:</strong> Number of threads to use. If None, the number of threads is automatically determined.</li><li><strong>repeat_penalty:</strong> The penalty to apply to repeated tokens. Defaults to <code>1.1</code>.</li><li><strong>seed:</strong> Seed. If -1, a random seed is used. Defaults to <code>-1</code>.</li><li><strong>stop:</strong> A list of strings to stop generation when encountered.</li><li><strong>streaming:</strong> Whether to stream the results, token by token. Defaults to <code>True</code>.</li><li><strong>suffix:</strong> A suffix to append to the generated text. If None, no suffix is appended.</li><li><strong>tags:</strong> Tags to add to the run trace.</li><li><strong>temperature:</strong> The temperature to use for sampling. Defaults to <code>0.8</code>.</li><li><strong>top_k:</strong> The top-k value to use for sampling. Defaults to <code>40</code>.</li><li><strong>top_p:</strong> The top-p value to use for sampling. Defaults to <code>0.95</code>.</li><li><strong>use_mlock:</strong> Force the system to keep the model in RAM. Defaults to <code>False</code>.</li><li><strong>use_mmap:</strong> Whether to keep the model loaded in RAM. Defaults to <code>True</code>.</li><li><strong>verbose:</strong> This parameter is used to control the level of detail in the output of the chain. When set to True, it will print out some internal states of the chain while it is being run, which can help debug and understand the chain&#x27;s behavior. If set to False, it will suppress the verbose output. Defaults to <code>False</code>.</li><li><strong>vocab_only:</strong> Only load the vocabulary, no weights. Defaults to <code>False</code>.</li></ul><hr><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="openai">OpenAI<a href="#openai" class="hash-link" aria-label="Direct link to OpenAI" title="Direct link to OpenAI">​</a></h3><p>Wrapper around <a href="https://openai.com" target="_blank" rel="noopener noreferrer">OpenAI&#x27;s</a> large language models.</p><ul><li><strong>max_tokens:</strong> The maximum number of tokens to generate in the completion. <code>-1</code> returns as many tokens as possible, given the prompt and the model&#x27;s maximal context size – defaults to <code>256</code>.</li><li><strong>model_kwargs:</strong> Holds any model parameters valid for creating non-specified calls.</li><li><strong>model_name:</strong> Defines the OpenAI model to be used.</li><li><strong>openai_api_base:</strong> Used to specify the base URL for the OpenAI API. It is typically set to the API endpoint provided by the OpenAI service.</li><li><strong>openai_api_key:</strong>  Key used to authenticate and access the OpenAI API.</li><li><strong>temperature:</strong> Tunes the degree of randomness in text generations. Should be a non-negative value – defaults to <code>0.7</code>.</li></ul><hr><h3 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="vertexai">VertexAI<a href="#vertexai" class="hash-link" aria-label="Direct link to VertexAI" title="Direct link to VertexAI">​</a></h3><p>Wrapper around <a href="https://cloud.google.com/vertex-ai" target="_blank" rel="noopener noreferrer">Google Vertex AI</a> large language models.</p><div class="theme-admonition theme-admonition-info alert alert--info admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_S0QG"><p>Vertex AI is a cloud computing platform offered by Google Cloud Platform (GCP). It provides access, management, and development of applications and services through global data centers. To use Vertex AI PaLM, you need to have the <a href="https://pypi.org/project/google-cloud-aiplatform/" target="_blank" rel="noopener noreferrer">google-cloud-aiplatform</a> Python package installed and credentials configured for your environment.</p></div></div><ul><li><strong>credentials:</strong> The default custom credentials (google.auth.credentials.Credentials) to use.</li><li><strong>location:</strong> The default location to use when making API calls – defaults to <code>us-central1</code>.</li><li><strong>max_output_tokens:</strong> Token limit determines the maximum amount of text output from one prompt – defaults to <code>128</code>.</li><li><strong>model_name:</strong> The name of the Vertex AI large language model – defaults to <code>text-bison</code>.</li><li><strong>project:</strong> The default GCP project to use when making Vertex API calls.</li><li><strong>request_parallelism:</strong> The amount of parallelism allowed for requests issued to VertexAI models – defaults to <code>5</code>.</li><li><strong>temperature:</strong> Tunes the degree of randomness in text generations. Should be a non-negative value – defaults to <code>0</code>.</li><li><strong>top_k:</strong> How the model selects tokens for output, the next token is selected from – defaults to <code>40</code>.</li><li><strong>top_p:</strong> Tokens are selected from most probable to least until the sum of their – defaults to <code>0.95</code>.</li><li><strong>tuned_model_name:</strong> The name of a tuned model. If provided, model_name is ignored.</li><li><strong>verbose:</strong> This parameter is used to control the level of detail in the output of the chain. When set to True, it will print out some internal states of the chain while it is being run, which can help debug and understand the chain&#x27;s behavior. If set to False, it will suppress the verbose output – defaults to <code>False</code>.</li></ul></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/components/embeddings"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Embeddings</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/components/loaders"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Loaders</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#anthropic" class="table-of-contents__link toc-highlight">Anthropic</a></li><li><a href="#chatanthropic" class="table-of-contents__link toc-highlight">ChatAnthropic</a></li><li><a href="#ctransformers" class="table-of-contents__link toc-highlight">CTransformers</a></li><li><a href="#chatopenai" class="table-of-contents__link toc-highlight">ChatOpenAI</a></li><li><a href="#cohere" class="table-of-contents__link toc-highlight">Cohere</a></li><li><a href="#huggingfacehub" class="table-of-contents__link toc-highlight">HuggingFaceHub</a></li><li><a href="#llamacpp" class="table-of-contents__link toc-highlight">LlamaCpp</a></li><li><a href="#openai" class="table-of-contents__link toc-highlight">OpenAI</a></li><li><a href="#vertexai" class="table-of-contents__link toc-highlight">VertexAI</a></li></ul></div></div></div></div></main></div></div><footer class="footer"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Logspace.</div></div></div></footer><div style="background-color:#f6f6f6" class="ms-rotate-0 ms-fixed ms-bottom-4 ms-right-8 ms-z-[100] ms-flex ms-flex-col ms-items-center ms-justify-center ms-rounded-md ms-p-2 ms-transition"><div class="ms-rotate-0 ms-flex ms-h-full ms-w-full ms-transform ms-cursor-pointer ms-items-center ms-justify-center ms-rounded-full ms-transition-all ms-delay-75 ms-duration-100 ms-ease-in-out"><div style="color:#000000;font-size:22px;width:48px;height:48px;margin:0px;padding:0px;display:flex;align-items:center;justify-content:center;text-align:center"><img src="/img/chain.png" style="width:40px"></div></div><div style="color:#000000" class="ms-rounded-md ms-bg-white ms-bg-opacity-10 ms-p-1 ms-text-base ms-text-sm ms-transition-all ms-delay-75 ms-mt-2 ms-scale-100">CTRL + K</div></div></div>
<script src="/assets/js/runtime~main.9bb0729e.js"></script>
<script src="/assets/js/main.7b375ee0.js"></script>
</body>
</html>